"""
–ü–æ–≤–Ω–∏–π pipeline:
- –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è PDF ‚Üí –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
- OCR
- –í–∏—Ç—è–≥ —Ç–µ–∫—Å—Ç—É –∑–∞–¥–∞—á
- –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Ç–µ–æ—Ä—ñ—ó —á–µ—Ä–µ–∑ LLM
- –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ –±–∞–∑—É
"""

import os
from education.models import Item, TheoryPractice
from utils.llm_client import send_llm_prompt
from pdf2image import convert_from_path
from PIL import Image
import pytesseract

# --- –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è ---
TESSERACT_CMD = r"C:\Program Files\Tesseract-OCR\tesseract.exe"
POPPLER_PATH = r"C:\Program Files\poppler-24\Library\bin"
MEDIA_IMAGE_DIR = "media/ocr_pages"
LANG = "ukr"
GRADE = 5
PDF_PATH = f"static/{GRADE}_klas_matematika.pdf"

pytesseract.pytesseract.tesseract_cmd = TESSERACT_CMD
os.makedirs(MEDIA_IMAGE_DIR, exist_ok=True)


def ocr_pdf(pdf_path):
    images = convert_from_path(pdf_path, dpi=300, poppler_path=POPPLER_PATH)
    pages = []
    for i, img in enumerate(images):
        image_path = os.path.join(MEDIA_IMAGE_DIR, f"page_{i+1:03}.png")
        img.save(image_path, "PNG")
        text = pytesseract.image_to_string(img, lang=LANG)
        pages.append((i + 1, text))
    return pages


def extract_context(page_text, item_text, radius=3):
    lines = page_text.splitlines()
    for i, line in enumerate(lines):
        if item_text.lower()[:10] in line.lower():
            start = max(i - radius, 0)
            end = min(i + radius + 1, len(lines))
            return "\n".join(lines[start:end])
    return ""


def generate_theory(item_text, grade, context_text):
    prompt = (
        f"–¢–∏ ‚Äî –≤—á–∏—Ç–µ–ª—å –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ –¥–ª—è {grade} –∫–ª–∞—Å—É. "
        f"–°—Ç–≤–æ—Ä–∏ –∫–æ—Ä–æ—Ç–∫–µ –ø–æ—è—Å–Ω–µ–Ω–Ω—è —Ç–µ–æ—Ä—ñ—ó –Ω–∞ —Ç–µ–º—É: ¬´{item_text}¬ª. "
        f"–í—Ä–∞—Ö—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∑ –ø—ñ–¥—Ä—É—á–Ω–∏–∫–∞:\n{context_text}"
    )
    return send_llm_prompt(prompt)


def run_pipeline():
    print(f"üîç –û–±—Ä–æ–±–ª—è—î–º–æ PDF: {PDF_PATH}")
    pages = ocr_pdf(PDF_PATH)

    items = Item.objects.all()
    for item in items:
        item_text = item.content.strip()
        found = False
        for page_num, page_text in pages:
            if item_text[:10].lower() in page_text.lower():
                context = extract_context(page_text, item_text)
                theory = generate_theory(item_text, GRADE, context)
                TheoryPractice.objects.update_or_create(
                    item=item,
                    defaults={"theory": theory}
                )
                print(f"‚úÖ –¢–µ–æ—Ä—ñ—é –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ –¥–ª—è Item {item.id} (—Å—Ç–æ—Ä—ñ–Ω–∫–∞ {page_num})")
                found = True
                break
        if not found:
            print(f"‚ö†Ô∏è –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ —Ç–µ–æ—Ä—ñ—ó –¥–ª—è Item {item.id}: {item_text[:50]}")


if __name__ == "__main__":
    run_pipeline()
